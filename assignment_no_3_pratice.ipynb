{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9823d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The quick brown fox jumps over the lazy dog.\n",
      "Cleaned: quick brown fox jump lazy dog\n",
      "\n",
      "Original: This is a sample document for testing the bag of words function.\n",
      "Cleaned: sample document testing bag word function\n",
      "\n",
      "Original: NLTK provides useful useful tools for text preprocessing.\n",
      "Cleaned: nltk provides useful useful tool text preprocessing\n",
      "\n",
      "Original: Bag of words is a simple and effective method for text representation.\n",
      "Cleaned: bag word simple effective method text representation\n",
      "\n",
      "Original: Machine learning algorithms often use bag of words as input features.\n",
      "Cleaned: machine learning algorithm often use bag word input feature\n",
      "\n",
      "TF-IDF Representation:\n",
      "   algorithm       bag     brown  document       dog  effective   feature  \\\n",
      "0   0.000000  0.000000  0.408248  0.000000  0.408248   0.000000  0.000000   \n",
      "1   0.000000  0.302637  0.000000  0.451891  0.000000   0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
      "3   0.000000  0.284329  0.000000  0.000000  0.000000   0.424555  0.000000   \n",
      "4   0.355851  0.238318  0.000000  0.000000  0.000000   0.000000  0.355851   \n",
      "\n",
      "        fox  function     input  ...  representation    sample    simple  \\\n",
      "0  0.408248  0.000000  0.000000  ...        0.000000  0.000000  0.000000   \n",
      "1  0.000000  0.451891  0.000000  ...        0.000000  0.451891  0.000000   \n",
      "2  0.000000  0.000000  0.000000  ...        0.000000  0.000000  0.000000   \n",
      "3  0.000000  0.000000  0.000000  ...        0.424555  0.000000  0.424555   \n",
      "4  0.000000  0.000000  0.355851  ...        0.000000  0.000000  0.000000   \n",
      "\n",
      "    testing      text      tool       use    useful      word  label  \n",
      "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000      2  \n",
      "1  0.451891  0.000000  0.000000  0.000000  0.000000  0.302637      3  \n",
      "2  0.000000  0.274304  0.339992  0.000000  0.679984  0.000000      1  \n",
      "3  0.000000  0.342528  0.000000  0.000000  0.000000  0.284329      1  \n",
      "4  0.000000  0.000000  0.000000  0.355851  0.000000  0.238318      0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "Label Encoder Mapping:\n",
      "        label  encoded_label\n",
      "0      animal              2\n",
      "1  sample doc              3\n",
      "2         NLP              1\n",
      "3         NLP              1\n",
      "4          ML              0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"This is a sample document for testing the bag of words function.\",\n",
    "    \"NLTK provides useful useful tools for text preprocessing.\",\n",
    "    \"Bag of words is a simple and effective method for text representation.\",\n",
    "    \"Machine learning algorithms often use bag of words as input features.\"\n",
    "]\n",
    "\n",
    "# Label Encoding\n",
    "labels = ['animal', 'sample doc', 'NLP', 'NLP', 'ML']\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    clean_text = ' '.join(tokens)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "# Preprocess documents\n",
    "clean_documents = [preprocess_text(doc) for doc in documents]\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Create TF-IDF representations\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(clean_documents)\n",
    "\n",
    "# Convert TF-IDF matrix to DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add labels to DataFrame\n",
    "tfidf_df['label'] = encoded_labels\n",
    "\n",
    "# Save outputs\n",
    "tfidf_df.to_csv('tfidf_representation.csv', index=False)\n",
    "label_encoder_mapping = pd.DataFrame({'label': labels, 'encoded_label': encoded_labels})\n",
    "label_encoder_mapping.to_csv('label_encoder_mapping.csv', index=False)\n",
    "\n",
    "# Output the preprocessed documents\n",
    "for doc, clean_doc in zip(documents, clean_documents):\n",
    "    print(f\"Original: {doc}\")\n",
    "    print(f\"Cleaned: {clean_doc}\")\n",
    "    print()\n",
    "\n",
    "# Display TF-IDF DataFrame\n",
    "print(\"TF-IDF Representation:\")\n",
    "print(tfidf_df)\n",
    "\n",
    "# Display Label Encoder Mapping\n",
    "print(\"Label Encoder Mapping:\")\n",
    "print(label_encoder_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69aa509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
